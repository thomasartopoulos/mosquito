{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mosquito_LaNación.ipynb","provenance":[{"file_id":"1Y5SNyTxjCjmY5Byz8AUwhCiJj38BKWCL","timestamp":1600194673650}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xIajTvFZLHlS","outputId":"e0e23aba-5c28-4312-e8f5-5dfcd9b78aec"},"source":["!pip install TwitterAPI\n","!pip install -U kaleido\n","!pip install orca==1.2.1\n","!pip install plotly==4.7.1\n","!wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n","!chmod +x /usr/local/bin/orca\n","!apt-get install xvfb libgtk2.0-0 libgconf-2-4\n","import requests\n","import json\n","from operator import itemgetter\n","from bs4 import BeautifulSoup\n","import networkx as nx\n","from TwitterAPI import TwitterAPI\n","import urllib\n","from math import pi\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","from skimage import io\n","from io import BytesIO\n","import datetime\n","from wordcloud import WordCloud, STOPWORDS\n","from PIL import Image\n","import random\n","from plotly.offline import init_notebook_mode, iplot\n","import plotly.express as ex\n","import plotly.graph_objs as go\n","import requests\n","import json\n","from operator import itemgetter\n","from bs4 import BeautifulSoup\n","import plotly.graph_objects as go\n","import networkx as nx\n","from TwitterAPI import TwitterAPI\n","import urllib\n","from math import pi\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","from skimage import io\n","from io import BytesIO\n","import datetime\n","from wordcloud import WordCloud, STOPWORDS\n","from PIL import Image\n","import random\n","\n","outliers = [\"sa\",\"protegido\",\"comentario\",\"reglamento\",\"copyright\",\"cuenta\",\"miembro\",\"nacion\",\"club\",\"diarios\",\"home\",\"gda\",\"recaptcha\",\"Palabras\",\"lunes\",\"martes\",\"miércoles\",\"miercoles\",\"jueves\",\"viernes\",\"sábado\",\"sabado,\",\"domingo\",\"dtype\",\"Frecuencia\",'buena', 'cinco', 'tan', 'camino',  'posible', 'local', 'junto' , 'final', 'iba',  'grupo', 'medida',  'explicó', 'dio', 'viernes',  'aún', 'estamos', 'lado', 'nueva', 'agregó', 'respecto', 'ella', 'partir',  'tema', 'zona', 'centro', 'hubo', 'tenemos', 'unos',  'hombre', 'sea', 'llegar', 'dentro', 'información', 'estas',  'veces', 'bajo', 'esos', 'entonces', 'nunca', 'hacia', 'sí', 'quedó', 'hecho', 'misma', 'mil', 'chicos', 'sigue', 'fin', 'decir', 'volver', 'allí', 'nada',  'quienes', 'muchos', 'decisión', 'importante', 'frente', 'estados', 'será', 'relación', 'pasó', 'poder', 'total', 'ir', 'debe', 'pueden',  'sino',  'otras', 'haber', 'través', 'causa', 'mes',  'dice', 'nuevo', 'mejor', 'ver', 'cuerpo', 'estar', 'tenía', 'casi', 'poco', 'primer', 'llegó', 'sólo', 'gente', 'cosas', 'estos', 'mayor', 'primera','algunos', 'mucho', 'forma', 'sido', 'siempre', 'hizo',  'va', 'algo', 'han', 'tienen',  'te', 'aires', 'medio', 'todas', 'él', 'horas', 'tras', 'ellos', 'meses', 'estaba', 'aunque', 'gran', 'antes', 'tener',  'fueron', 'les', 'us', 'menos', 'ante', 'esto', 'otra',  'tanto', 'e', 'pasado', 'solo', 'vida', 'manera', 'semana', 'ni', 'buenos', 'día', 'momento', 'luego', 'tiempo', 'bien', 'otro', 'qué', 'mientras', 'mismo', 'martes', 'otros', 'cómo', 'tres', 'dólares', 'hacer', 'yo', 'contra', 'lunes', 'hace', 'nos', 'están','quien', 'además', 'así', 'lugar', 'uno', 'después', 'durante', 'mi', 'hoy', 'vez', 'año', 'días', 'según', 'país', 'esa', 'cada', 'ahora', 'personas', 'eso', 'puede', 'muy', 'parte', 'dijo', 'era', 'argentina', 'todos', 'ha', 'tiene', 'donde', 'porque', 'ser', 'ese', 'millones', 'todo', 'hasta', 'dos', 'había', 'esta', 'sin', 'son', 'está', 'cuando', 'ya', 'años', 'me', 'hay', 'también', 'entre', 'si', 'sobre', 'sus', 'desde', 'o', 'le', 'este', 'fue', 'pero', 'como', 'más', 'lo', 'su', 'al', 'es', 'no', 'para', 'una', 'con', 'las', 'por', 'un', 'quot', 'se', 'del', 'los', 'a', 'y', 'en', 'que','el','la','de', 'términos','privacidad','reservado','derechos','condiciones','ar','enerodni','www','reservados']\n","\n","\n","def make_edge(x, y, text, width):\n","    return  go.Scatter(x         = x,\n","                       y         = y,\n","                       line      = dict(width = width,\n","                                   color = 'cornflowerblue'),\n","                       hoverinfo = 'text',\n","                       text      = ([text]),\n","                       mode      = 'lines')\n","    \n","def seccionLinks(url,seccion):\n","  linkanterior = \"\"\n","  linksadevolver = []\n","  req = requests.get(url)\n","  soup = BeautifulSoup(req.text, \"lxml\")\n","  lista = soup.find_all('a')\n","  indice =0\n","  while indice<len(lista):\n","    link = lista[indice].get('href')\n","    i =0\n","    categoria = \"\"\n","    contadorbarras =0\n","    if link != None:\n","      while i<len(link):\n","        if contadorbarras==0 and link[i] == \"/\":\n","          contadorbarras=1\n","        elif contadorbarras == 1:\n","          if link[i]!= \"/\":\n","            categoria+=link[i]\n","          else :\n","            contadorbarras = 2\n","        i+=1\n","      if categoria==seccion:\n","        if(link!=linkanterior):\n","          linkanterior=link\n","          linksadevolver.append(link)\n","    indice+=1\n","  return linksadevolver\n","\n","def palabrasArticulo(url):\n","  palabras = []\n","  req = requests.get(url)\n","  soup = BeautifulSoup(req.text, \"lxml\")\n","  #juan = json.loads(soup.find('script',type=\"application/ld+json\").text)\n","  juan = soup.find_all('p')\n","  for items in juan:\n","    if items.get_text() != 'República Argentina | Todos los derechos reservados | Política de privacidad | Términos y Condiciones© 2000-2020 www.pagina12.com.ar':\n","      palabras+=separaPalabras(items.get_text())\n","  #palabras+=(separaPalabras(juan[\"alternativeHeadline\"]))\n","  #palabras+=(separaPalabras(juan[\"articleBody\"]))\n","  return palabras\n","\n","\n","def palabrasArticuloBis(url):\n","  frases = []\n","  req = requests.get(url)\n","  soup = BeautifulSoup(req.text, \"lxml\")\n","  juan = soup.find_all('p')\n","  for items in juan:\n","    if items.get_text() != 'República Argentina | Todos los derechos reservados | Política de privacidad | Términos y Condiciones© 2000-2020 www.pagina12.com.ar':\n","      frases+=(separaFrases(items.get_text()))\n","  return frases\n","\n","\n","def separaPalabras(frase):\n","  palabras=[]\n","  i =0\n","  while i<len(frase):\n","    if frase[i].isalpha():\n","      h=i+1\n","      while h<len(frase):\n","        if h==len(frase)-1:\n","          if frase[h].isalpha():\n","            if frase[i:h+1].lower() not in outliers:\n","              palabras.append(frase[i:h+1].lower())\n","          else :\n","            if frase[i:h].lower() not in outliers:\n","              palabras.append(frase[i:h].lower())\n","          i = len(frase)\n","        elif frase[h].isalpha()!= True:\n","          if frase[i:h].lower() not in outliers:\n","            palabras.append(frase[i:h].lower())\n","          i = h         \n","          h = len(frase)\n","        h+=1\n","    i+=1\n","  return palabras\n","\n","def separaFrases(frase):\n","  palabras=[]\n","  i =0\n","  while i<len(frase):\n","    h=i+1\n","    while h<len(frase):\n","      if h==len(frase)-1:\n","        palabras.append(frase[i:h])\n","        i = len(frase)\n","      elif frase[h]== \".\":\n","        palabras.append(frase[i:h])\n","        i = h       \n","        h = len(frase)\n","      h+=1\n","    i+=1\n","  return palabras\n","\n","def relacionaPalabras(frase,relacionadorDePalabras):\n","  i = 0\n","  while i < len(frase)-1:\n","    h = i+1\n","    while h < len(frase):\n","      if frase[i] in relacionadorDePalabras and frase[h] in relacionadorDePalabras[frase[i]]:\n","        relacionadorDePalabras[frase[i]][frase[h]] +=1\n","        relacionadorDePalabras[frase[h]][frase[i]] +=1\n","      else:\n","        if frase[i] in relacionadorDePalabras:\n","          relacionadorDePalabras[frase[i]][frase[h]] = 1\n","          if frase[h] in relacionadorDePalabras:\n","            relacionadorDePalabras[frase[h]][frase[i]] = 1\n","          else:\n","            relacionadorDePalabras[frase[h]] = {}\n","            relacionadorDePalabras[frase[h]][frase[i]] = 1\n","        else:\n","          relacionadorDePalabras[frase[i]] = {}\n","          relacionadorDePalabras[frase[i]][frase[h]] = 1\n","          if frase[h] in relacionadorDePalabras:\n","            relacionadorDePalabras[frase[h]][frase[i]] = 1\n","          else:\n","            relacionadorDePalabras[frase[h]] = {}\n","            relacionadorDePalabras[frase[h]][frase[i]] = 1\n","      h+=1\n","    i+=1\n","\n","def palabrasMaspalabrasMenos(palabras):\n","  tuplaPalabras = []\n","  i = 0\n","  while i<len(palabras):\n","    palabreta = palabras[i]\n","    loEncontro = False\n","    h = 0\n","    while h<len(tuplaPalabras):\n","      if palabreta==tuplaPalabras[h][0]:\n","        loEncontro = True\n","        nuevatupla = (tuplaPalabras[h][0],tuplaPalabras[h][1]+1)\n","        tuplaPalabras[h]= nuevatupla\n","        h = len(tuplaPalabras)\n","      h+=1\n","    if loEncontro == False:\n","      tupla = (palabreta,1)\n","      tuplaPalabras.append(tupla)\n","    i+=1\n","  return sorted(tuplaPalabras, key=itemgetter(1))\n","\n","\n","def color_func_clarin(word, font_size, position, orientation, random_state=None,**kwargs):\n","  return \"hsl(239, 100%, 40%)\"\n","\n","def hello_world(request):\n","  outliers = [\"copyright\",\"cuenta\",\"miembro\",\"nacion\",\"club\",\"diarios\",\"home\",\"gda\",\"recaptcha\",\"Palabras\",\"lunes\",\"martes\",\"miércoles\",\"miercoles\",\"jueves\",\"viernes\",\"sábado\",\"sabado,\",\"domingo\",\"dtype\",\"Frecuencia\",'buena', 'cinco', 'tan', 'camino',  'posible', 'local', 'junto' , 'final', 'iba',  'grupo', 'medida',  'explicó', 'dio', 'viernes',  'aún', 'estamos', 'lado', 'nueva', 'agregó', 'respecto', 'ella', 'partir',  'tema', 'zona', 'centro', 'hubo', 'tenemos', 'unos',  'hombre', 'sea', 'llegar', 'dentro', 'información', 'estas',  'veces', 'bajo', 'esos', 'entonces', 'nunca', 'hacia', 'sí', 'quedó', 'hecho', 'misma', 'mil', 'chicos', 'sigue', 'fin', 'decir', 'volver', 'allí', 'nada',  'quienes', 'muchos', 'decisión', 'importante', 'frente', 'estados', 'será', 'relación', 'pasó', 'poder', 'total', 'ir', 'debe', 'pueden',  'sino',  'otras', 'haber', 'través', 'causa', 'mes',  'dice', 'nuevo', 'mejor', 'ver', 'cuerpo', 'estar', 'tenía', 'casi', 'poco', 'primer', 'llegó', 'sólo', 'gente', 'cosas', 'estos', 'mayor', 'primera','algunos', 'mucho', 'forma', 'sido', 'siempre', 'hizo',  'va', 'algo', 'han', 'tienen',  'te', 'aires', 'medio', 'todas', 'él', 'horas', 'tras', 'ellos', 'meses', 'estaba', 'aunque', 'gran', 'antes', 'tener',  'fueron', 'les', 'us', 'menos', 'ante', 'esto', 'otra',  'tanto', 'e', 'pasado', 'solo', 'vida', 'manera', 'semana', 'ni', 'buenos', 'día', 'momento', 'luego', 'tiempo', 'bien', 'otro', 'qué', 'mientras', 'mismo', 'martes', 'otros', 'cómo', 'tres', 'dólares', 'hacer', 'yo', 'contra', 'lunes', 'hace', 'nos', 'están','quien', 'además', 'así', 'lugar', 'uno', 'después', 'durante', 'mi', 'hoy', 'vez', 'año', 'días', 'según', 'país', 'esa', 'cada', 'ahora', 'personas', 'eso', 'puede', 'muy', 'parte', 'dijo', 'era', 'argentina', 'todos', 'ha', 'tiene', 'donde', 'porque', 'ser', 'ese', 'millones', 'todo', 'hasta', 'dos', 'había', 'esta', 'sin', 'son', 'está', 'cuando', 'ya', 'años', 'me', 'hay', 'también', 'entre', 'si', 'sobre', 'sus', 'desde', 'o', 'le', 'este', 'fue', 'pero', 'como', 'más', 'lo', 'su', 'al', 'es', 'no', 'para', 'una', 'con', 'las', 'por', 'un', 'quot', 'se', 'del', 'los', 'a', 'y', 'en', 'que','el','la','de', 'términos','privacidad','reservado','derechos','condiciones','ar','enerodni','www','reservados']\n","  x = datetime.datetime.now()\n","  fechaHoy = str(x.day)+\"/\"+str(x.month)+\"/\"+str(x.year)\n","  secciones = {\"politica\":[],\"economia\":[],\"sociedad\":[],\"deportes\":[],\"espectaculos\":[],\"el-mundo\":[],\"opinion\":[],\"ultimas-noticias\":[]}\n","  total = []\n","  relacionador = {}\n","  listadeerrores = \"\"\n","  for keys in secciones:\n","    articulos = seccionLinks('https://www.lanacion.com.ar/'+keys,keys)\n","    for articulo in articulos:\n","      #try:\n","      frases = palabrasArticuloBis('https://www.lanacion.com.ar/'+articulo)\n","      for frase in frases:\n","        relacionaPalabras(separaPalabras(frase),relacionador)\n","      secciones[keys] += palabrasArticulo('https://www.lanacion.com.ar/'+articulo)   \n","      total += palabrasArticulo('https://www.lanacion.com.ar/'+articulo)\n","      #except Exception as e:\n","      #listadeerrores+= str(e)\n","  for keys in secciones:\n","    secciones[keys] = palabrasMaspalabrasMenos(secciones[keys])\n","  total = palabrasMaspalabrasMenos(total)\n","\n","  consumer_key = \"7SnulbvNSSsRCoExpLOcFzuEk\"\n","  consumer_secret = \"GOl0GlxQOTTm2z6DGgOdhRNQGEPkzjLXEeFcoTKLFxeOGmimNx\"\n","  access_token = \"1325109247735107585-4I2ciupiOOoLWvDVfnqhTUtxWG2VRP\"\n","  access_token_secret = \"HoogPc1hM0PDSfrfo9U9y9sJqVQCGwGlbgVvbjNXIsflO\"\n","\n","  CONSUMER_KEY = consumer_key\n","  CONSUMER_SECRET = consumer_secret\n","  ACCESS_TOKEN_KEY = access_token\n","  ACCESS_TOKEN_SECRET = access_token_secret\n","\n","  api = TwitterAPI(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN_KEY, ACCESS_TOKEN_SECRET)\n","  #arrancanetwork\n","  registrador = {}\n","  eliminar = []\n","  miNet = nx.Graph()\n","  listadeGrandes = []\n","  diccionarioTamNodos = {}\n","\n","  for palabra in relacionador:\n","    tamNodo = 0\n","    for keys in secciones:\n","      for tuplas in secciones[keys]:\n","        if tuplas[0] == palabra:\n","          tamNodo+= tuplas[1]\n","    diccionarioTamNodos[palabra] = tamNodo\n","    if len(listadeGrandes)<16:\n","        listadeGrandes.append(palabra)\n","    else:\n","      menor = palabra\n","      posicion = 100\n","      for palabre in listadeGrandes:\n","        if diccionarioTamNodos[palabre]<diccionarioTamNodos[menor]:\n","          menor = palabre\n","          posicion = listadeGrandes.index(palabre)\n","      if menor != palabra:\n","        listadeGrandes[posicion]=palabra\n","  \n","  \n","  for palabras in listadeGrandes:\n","    miNet.add_node(palabras,size = diccionarioTamNodos[palabras]/50)\n","\n","  indice = 0\n","  while indice < len(listadeGrandes)-1:\n","    indice2 = indice+1\n","    while indice2 < len(listadeGrandes):\n","      tamTrace = 0\n","      if listadeGrandes[indice2] in relacionador[listadeGrandes[indice]]:\n","        if relacionador[listadeGrandes[indice]][listadeGrandes[indice2]]> min(diccionarioTamNodos[listadeGrandes[indice]]/50,diccionarioTamNodos[listadeGrandes[indice2]]/50):\n","          tamTrace = min(diccionarioTamNodos[listadeGrandes[indice]]/50,diccionarioTamNodos[listadeGrandes[indice2]]/50)\n","        else:\n","          tamTrace = relacionador[listadeGrandes[indice]][listadeGrandes[indice2]]\n","        miNet.add_edge(listadeGrandes[indice], listadeGrandes[indice2], weight = (tamTrace))\n","      indice2+=1\n","    indice+=1\n","\n","  pos_ = nx.spring_layout(miNet)\n","\n","  edge_trace = []\n","  for edge in miNet.edges():\n","    char_1 = edge[0]\n","    char_2 = edge[1]\n","    x0, y0 = pos_[char_1]\n","    x1, y1 = pos_[char_2]\n","    text   = char_1 + '--' + char_2 + ': ' + str(miNet.edges()[edge]['weight'])\n","    trace  = make_edge([x0, x1, None], [y0, y1, None], text, width = 0.3*miNet.edges()[edge]['weight']**1.75)\n","    edge_trace.append(trace)\n","\n","  # Make a node trace\n","  node_trace = go.Scatter(x         = [],\n","                          y         = [],\n","                          text      = [],\n","                          textposition = \"top center\",\n","                          textfont_size = 10,\n","                          mode      = 'markers+text',\n","                          hoverinfo = 'none',\n","                          marker    = dict(color = [],\n","                                          size  = [],\n","                                          line  = None))\n","\n","   # For each node in midsummer, get the position and size and add to the node_trace\n","  for node in miNet.nodes():\n","    x, y = pos_[node]\n","    node_trace['x'] += tuple([x])\n","    node_trace['y'] += tuple([y])\n","    node_trace['marker']['color'] += tuple(['cornflowerblue'])\n","    node_trace['marker']['size'] += tuple([5*miNet.nodes()[node]['size']])\n","    node_trace['text'] += tuple(['<b>' + node + '</b>'])\n","\n","  # Customize layout\n","  layout = go.Layout(\n","      #paper_bgcolor='rgba(0,0,0,0)',\n","      #plot_bgcolor='rgba(0,0,0,0)', \n","      xaxis =  {'showgrid': False, 'zeroline': False}, # no gridlines\n","      yaxis = {'showgrid': False, 'zeroline': False}, # no gridlines\n","  )# Create figure\n","  fig = go.Figure(layout = layout)# Add all edge traces\n","  print(\"los nodos estan\")\n","  for r in edge_trace:\n","    fig.add_trace(r)\n","\n","      # Add node trace\n","  fig.add_trace(node_trace)# Remove legend\n","  fig.update_layout(showlegend = False)# Remove tick labels\n","  fig.update_xaxes(showticklabels = False)\n","  fig.update_yaxes(showticklabels = False)\n","\n","  img_bytes = fig.to_image(format=\"png\")\n","  data = img_bytes\n","  statustw = 'Relacion de Palabras del dia La Nacion'\n","  r = api.request('statuses/update_with_media', {'status': statustw}, {'media[]':data})   \n","\n","  #arranca WordCloud\n","    \n","  url = \"https://i.ibb.co/hZD8yTt/mitre-2.jpg\"\n","  response = requests.get(url)\n","  clarin_mask = Image.open(BytesIO(response.content))\n","  stopwords = set(STOPWORDS)\n","  for word in outliers:\n","    stopwords.add(word)\n","  text = \"\"\n","  k=  len(total)-1\n","  while k>0 and k>(len(total)-1995):\n","    tupla= total[k]\n","    stringaux = \" \"+ tupla[0]        \n","    text+= stringaux\n","    k-=1\n","  clarin_mask = np.asanyarray(clarin_mask)\n","\n","\n","  \n","  try:\n","    wc_clarin = WordCloud(min_font_size = 1, background_color=\"white\",color_func= color_func_clarin, max_words=2000,mask= clarin_mask,\n","              stopwords=stopwords, contour_width=1, contour_color='white')\n","    wc_clarin.generate(text)\n","    \n","  except Exception as e:\n","    return listadeerrores\n","    \n","    \n","\n","  plt.axis(\"off\")\n","    # Ajustar el tamaño acá, en el figsize.\n","  plt.figure(figsize = (15,8))\n","  plt.imshow(wc_clarin, cmap=plt.cm.gray, interpolation='bilinear')\n","  plt.axis(\"off\")\n","  figfile = BytesIO()\n","  plt.savefig(figfile, format='png')\n","  data = figfile\n","  figfile.seek(0)  # rewind the data\n","  statustw = 'WordCloud La Nacion del dia' \n","  r = api.request('statuses/update_with_media', {'status': statustw}, {'media[]':data})   \n","  return \"hello world\"\n","\"\"\"\n","  ## Insteramos logo de Clarín\n","\n","  fig = plt.figure(figsize=(10,10))\n","  #ax = plt.subplot(121)\n","\n","  url = \"https://i.ibb.co/HXmGfs9/marx-final-retocada.jpg\"\n","  image = io.imread(url)\n","  #plt.imshow(image)\n","  #ax.axis(\"off\")\n","\n","  newax = fig.add_axes([0.10, 0.10, 0.20, 0.20], anchor='NE', zorder=-1)\n","  newax.imshow(image)\n","  newax.axis('off')\n","\n","  ## Secciones\n","  total = 0\n","\n","  secciones2 = {}\n","  for keys in secciones:\n","    secciones2[keys] = 0\n","    for items in secciones[keys]:\n","      secciones2[keys]+= items[1]\n","    total+= secciones2[keys]\n","  for keys in secciones2:\n","    secciones2[keys] = secciones2[keys] * 100 / total\n","  secciones3 = {}\n","  for keys in secciones2:\n","    secciones3[keys] = []\n","    secciones3[keys].append(secciones2[keys])\n","  \n","  df = pd.DataFrame({\n","    'group': ['LaIzquierdaDiario'],\n","\n","  })\n","  for keys in secciones3:\n","    df[keys] = secciones3[keys]\n","\n","  \n","  # number of variable\n","  categories=list(df)[1:]\n","  N = len(categories)\n","  \n","  # We are going to plot the first line of the data frame.\n","  # But we need to repeat the first value to close the circular graph:\n","  values=df.loc[0].drop('group').values.flatten().tolist()\n","  values += values[:1]\n","  values\n","  \n","  # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n","  angles = [n / float(N) * 2 * pi for n in range(N)]\n","  angles += angles[:1]\n","  \n","  # Initialise the spider plot\n","\n","  #ax = plt.subplot(111, polar=True)\n","  fig, ax = plt.subplots(figsize=(10,10), subplot_kw=dict(polar=True))\n","\n","  # Draw one axe per variable + add labels labels yet\n","  plt.xticks(angles[:-1], categories, color='black', size=20)\n","\n","\n","  # Draw ylabels\n","  ax.set_rlabel_position(0)\n","  plt.yticks([10,20,30], [\"10\",\"20\",\"30\"], color=\"grey\", size=10)\n","  plt.ylim(0,20)\n","  \n","  # Plot data\n","  ax.plot(angles, values, linewidth=1, linestyle='solid',color='red')\n","  \n","  # Fill area\n","  ax.fill(angles, values, 'b',color=\"red\", alpha=0.1)\n","\n","\n","  ## Acá le cambiamos el color de fondo\n","  #fig.set_facecolor(\"red\")\n","\n","\n","  ## Acomodamos las secciones\n","\n","  for label,i in zip(ax.get_xticklabels(),range(0,len(angles))):\n","\n","      angle_rad=angles[i]\n","      if angle_rad <= pi/2:\n","          ha= 'left'\n","          va= \"bottom\"\n","\n","      elif pi/2 < angle_rad <= pi:\n","          ha= 'right'\n","          va= \"bottom\"\n","\n","      elif pi < angle_rad <= (3*pi/2):\n","          ha= 'right'\n","          va= \"top\"  \n","\n","      else:\n","          ha= 'right'\n","          va= \"bottom\"\n","\n","      label.set_verticalalignment(va)\n","      label.set_horizontalalignment(ha)\n","  \n","  figfile = BytesIO()\n","  plt.savefig(figfile, format='png')\n","  data = figfile\n","  figfile.seek(0)  # rewind the data\n","\n","  plt.close(fig)\n","  statustw = 'Radar de Palabras del dia ' + fechaHoy\n","  r = api.request('statuses/update_with_media', {'status': statustw}, {'media[]':data})\n","\"\"\"\n","\n","\n","hello_world(\"marx\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting TwitterAPI\n","  Downloading https://files.pythonhosted.org/packages/21/97/23706132272622456210ab91c81f51d8ed98525785c39f3b16347630973e/TwitterAPI-2.6.9.tar.gz\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from TwitterAPI) (2.23.0)\n","Requirement already satisfied: requests_oauthlib in /usr/local/lib/python3.6/dist-packages (from TwitterAPI) (1.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->TwitterAPI) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->TwitterAPI) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->TwitterAPI) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->TwitterAPI) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests_oauthlib->TwitterAPI) (3.1.0)\n","Building wheels for collected packages: TwitterAPI\n","  Building wheel for TwitterAPI (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for TwitterAPI: filename=TwitterAPI-2.6.9-cp36-none-any.whl size=13019 sha256=995801646dd50f93c004b8c0d9fd9851811908294608691026f4513f4a20369a\n","  Stored in directory: /root/.cache/pip/wheels/a5/0e/95/20cc6509adc448f64c2dd616bdc6fd25ce147b60ecfbc2c322\n","Successfully built TwitterAPI\n","Installing collected packages: TwitterAPI\n","Successfully installed TwitterAPI-2.6.9\n","Collecting kaleido\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/39/1c960a971f8d27e6aa4f1462dc048275c98bbb46f16871269ba941bb4a04/kaleido-0.1.0-py2.py3-none-manylinux1_x86_64.whl (74.6MB)\n","\u001b[K     |████████████████████████████████| 74.6MB 66kB/s \n","\u001b[?25hInstalling collected packages: kaleido\n","Successfully installed kaleido-0.1.0\n","\u001b[31mERROR: Could not find a version that satisfies the requirement orca==1.2.1 (from versions: 1.0.0, 1.1.0, 1.2.0, 1.3.0, 1.4.0, 1.5.1, 1.5.3, 1.5.4)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for orca==1.2.1\u001b[0m\n","Collecting plotly==4.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/78/eb6cbe96c8379c54819592bb228c58ed7386fcc60a55eca7db99432fdf14/plotly-4.7.1-py2.py3-none-any.whl (11.5MB)\n","\u001b[K     |████████████████████████████████| 11.5MB 9.8MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly==4.7.1) (1.15.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.7.1) (1.3.3)\n","Installing collected packages: plotly\n","  Found existing installation: plotly 4.4.1\n","    Uninstalling plotly-4.4.1:\n","      Successfully uninstalled plotly-4.4.1\n","Successfully installed plotly-4.7.1\n","--2021-02-22 18:57:11--  https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage\n","Resolving github.com (github.com)... 140.82.121.3\n","Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github-releases.githubusercontent.com/99037241/9dc3a580-286a-11e9-8a21-4312b7c8a512?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210222%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210222T185711Z&X-Amz-Expires=300&X-Amz-Signature=738e6a4d34ab48d1bbc670ad797ca043e5f64725af1f9d4f5b75718662a74ec2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=99037241&response-content-disposition=attachment%3B%20filename%3Dorca-1.2.1-x86_64.AppImage&response-content-type=application%2Foctet-stream [following]\n","--2021-02-22 18:57:11--  https://github-releases.githubusercontent.com/99037241/9dc3a580-286a-11e9-8a21-4312b7c8a512?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210222%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210222T185711Z&X-Amz-Expires=300&X-Amz-Signature=738e6a4d34ab48d1bbc670ad797ca043e5f64725af1f9d4f5b75718662a74ec2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=99037241&response-content-disposition=attachment%3B%20filename%3Dorca-1.2.1-x86_64.AppImage&response-content-type=application%2Foctet-stream\n","Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n","Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 51607939 (49M) [application/octet-stream]\n","Saving to: ‘/usr/local/bin/orca’\n","\n","/usr/local/bin/orca 100%[===================>]  49.22M  52.0MB/s    in 0.9s    \n","\n","2021-02-22 18:57:12 (52.0 MB/s) - ‘/usr/local/bin/orca’ saved [51607939/51607939]\n","\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2\n","  libgail-common libgail18 libgtk2.0-bin libgtk2.0-common\n","Suggested packages:\n","  gvfs\n","The following NEW packages will be installed:\n","  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2\n","  libgail-common libgail18 libgconf-2-4 libgtk2.0-0 libgtk2.0-bin\n","  libgtk2.0-common xvfb\n","0 upgraded, 11 newly installed, 0 to remove and 10 not upgraded.\n","Need to get 3,715 kB of archives.\n","After this operation, 17.2 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdbus-glib-1-2 amd64 0.110-2 [58.3 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gconf2-common all 3.2.6-4ubuntu1 [700 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgconf-2-4 amd64 3.2.6-4ubuntu1 [84.8 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gconf-service-backend amd64 3.2.6-4ubuntu1 [58.1 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gconf-service amd64 3.2.6-4ubuntu1 [2,036 B]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8 [784 kB]\n","Fetched 3,715 kB in 0s (24.2 MB/s)\n","Selecting previously unselected package libdbus-glib-1-2:amd64.\n","(Reading database ... 146442 files and directories currently installed.)\n","Preparing to unpack .../00-libdbus-glib-1-2_0.110-2_amd64.deb ...\n","Unpacking libdbus-glib-1-2:amd64 (0.110-2) ...\n","Selecting previously unselected package gconf2-common.\n","Preparing to unpack .../01-gconf2-common_3.2.6-4ubuntu1_all.deb ...\n","Unpacking gconf2-common (3.2.6-4ubuntu1) ...\n","Selecting previously unselected package libgconf-2-4:amd64.\n","Preparing to unpack .../02-libgconf-2-4_3.2.6-4ubuntu1_amd64.deb ...\n","Unpacking libgconf-2-4:amd64 (3.2.6-4ubuntu1) ...\n","Selecting previously unselected package gconf-service-backend.\n","Preparing to unpack .../03-gconf-service-backend_3.2.6-4ubuntu1_amd64.deb ...\n","Unpacking gconf-service-backend (3.2.6-4ubuntu1) ...\n","Selecting previously unselected package gconf-service.\n","Preparing to unpack .../04-gconf-service_3.2.6-4ubuntu1_amd64.deb ...\n","Unpacking gconf-service (3.2.6-4ubuntu1) ...\n","Selecting previously unselected package libgtk2.0-common.\n","Preparing to unpack .../05-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n","Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package libgtk2.0-0:amd64.\n","Preparing to unpack .../06-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n","Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package libgail18:amd64.\n","Preparing to unpack .../07-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n","Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package libgail-common:amd64.\n","Preparing to unpack .../08-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n","Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package libgtk2.0-bin.\n","Preparing to unpack .../09-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n","Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../10-xvfb_2%3a1.19.6-1ubuntu4.8_amd64.deb ...\n","Unpacking xvfb (2:1.19.6-1ubuntu4.8) ...\n","Setting up gconf2-common (3.2.6-4ubuntu1) ...\n","\n","Creating config file /etc/gconf/2/path with new version\n","Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n","Setting up libdbus-glib-1-2:amd64 (0.110-2) ...\n","Setting up xvfb (2:1.19.6-1ubuntu4.8) ...\n","Setting up libgconf-2-4:amd64 (3.2.6-4ubuntu1) ...\n","Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n","Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n","Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n","Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n","Setting up gconf-service-backend (3.2.6-4ubuntu1) ...\n","Setting up gconf-service (3.2.6-4ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MghlewpW3a8K"},"source":["Retorna cuantas veces aparece cada palabra "]},{"cell_type":"markdown","metadata":{"id":"JeCSGqyFpQWI"},"source":["Cosas para Sankey:"]},{"cell_type":"code","metadata":{"id":"Hjw2AyvspTku"},"source":["sources = []\n","targets = []\n","values = []\n","labels = []\n","labels.append(\"LaNación\")\n","for keys in secciones:\n","  labels.append(keys)\n","  sources.append(0)\n","  targets.append(len(labels)-1)\n","  cantPalabras = 0\n","  #print(str(len(secciones[keys])))\n","  for palabras in secciones[keys]:\n","    cantPalabras+= palabras[1]\n","  values.append(cantPalabras)\n","j=1\n","for keys in secciones: \n","  if len(secciones[keys])>=10:\n","    i = 0\n","    while i<5:\n","      sources.append(j)\n","      joan = secciones[keys] \n","      rudo = joan[len(secciones[keys])-1-i]\n","      labels.append(rudo[0])\n","      targets.append(len(labels)-1)\n","      values.append(rudo[1])\n","      i+=1\n","  else:\n","    print(keys)\n","  j+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0OJoWTaBpPfn"},"source":["!pip install chart_studio\n","import pandas as pd\n","import holoviews as hv\n","from holoviews import opts, dim\n","import urllib\n","import chart_studio.plotly as py\n","import numpy as np\n","\n","hv.extension('bokeh') \n","\n","#df = pd.DataFrame({\n","#  \"source\" : sources,\n","#    \"target\":target,\n","#    \"values\":values\n","#})\n","\n","#sankey = hv.Sankey(df, label='Palabras Clarin')\n","#sankey.opts(label_position='left', edge_color='target', node_color='target', cmap='tab20')\n","\n","import plotly.graph_objects as go\n","import urllib, json\n","\n","url = 'https://raw.githubusercontent.com/plotly/plotly.js/master/test/image/mocks/sankey_energy.json'\n","response = urllib.request.urlopen(url)\n","data = json.loads(response.read())\n","\n","# override gray link colors with 'source' colors\n","opacity = 0.4\n","# change 'magenta' to its 'rgba' value to add opacity\n","\n","data['data'][0]['node']['color'] = ['rgba(255,0,255, 0.8)' if color == \"magenta\" else color for color in data['data'][0]['node']['color']]\n","data['data'][0]['link']['color'] = [data['data'][0]['node']['color'][src].replace(\"0.8\", str(opacity))\n","                              for src in data['data'][0]['link']['source']]\n","#print(data['data'][0]['link']['target'])\n","#print(data['data'][0]['link']['value'])\n","#print(data['data'][0]['link']['label'])\n","fig = go.Figure(data=[go.Sankey(\n","    valueformat = \".0f\",\n","    valuesuffix = \"TWh\",\n","    # Define nodes\n","    node = dict(\n","      pad = 15,\n","      thickness = 15,\n","      line = dict(color = \"black\", width = 0.5),\n","      label =  labels,\n","      color =  data['data'][0]['node']['color']\n","    ),\n","    # Add links\n","   # data['data'][0]['link']['source'] = sources \n","   # data['data'][0]['link']['target']= targets\n","   # data['data'][0]['link']['value'] = values\n","    link = dict(\n","      source = sources,\n","      target =  targets,\n","      value =  values,\n","      label =  data['data'][0]['link']['label'],\n","      color =  data['data'][0]['link']['color']\n","))])\n","\n","fig.update_layout(title_text=\"Energy forecast for 2050<br>Source: Department of Energy & Climate Change, Tom Counsell via <a href='https://bost.ocks.org/mike/sankey/'>Mike Bostock</a>\",\n","                  font_size=10)\n","fig.show()"],"execution_count":null,"outputs":[]}]}